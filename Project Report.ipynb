{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Project 1\n",
        "subtitle: Precipitation Downscaling\n",
        "date: '2023-11-13'\n",
        "author: Riley Becker (rb111)\n",
        "echo: false\n",
        "number-sections: true\n",
        "code-annotations: hover\n",
        "kind: Project\n",
        "Module: '3'\n",
        "categories:\n",
        "  - Module 3\n",
        "  - Project\n",
        "format:\n",
        "  html:\n",
        "    toc-depth: 3\n",
        "  docx:\n",
        "    toc: true\n",
        "    toc-depth: 3\n",
        "    fig-format: png\n",
        "---"
      ],
      "id": "d716c937"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Executive Summary\n",
        "Global climate models are extremely valuable tools as they provide large scale estimates of climate data for wide-scale use. For this project, we were asked to use the ERA5 reanalysis temperature data to downscale precipitation data from the CPC local precipitation data. While global climate models offer climate data estimates for almost the entire world, they do have their drawbacks. One of these being the fact that it can be hard to use global climate models to model local-scale climate data. To help solve this issue that global climate models have, we can do whatâ€™s called downscaling to it to help offer higher resolution data at smaller scales. \n",
        "\n",
        "For this project, I developed a downscaling model that would build a model to downscale precipitation data from the temperature data through performing a principal component analysis and k-nearest neighbors model on the data. I also tried to run a random forest model on my data, but just could not get my code to work for it. I used principal component analysis to summarize the data in the large aggregated ERA5 Dataset to allow the data to be more easily analyzed. This data from the PCA was then inputted into a k-nearest neighbors model, which uses proximity to make predictions.\n",
        "\n",
        "# Exploratory Data Analysis\n",
        "## 1. Packages\n"
      ],
      "id": "d875d98a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import Pkg; Pkg.add(\"MultivariateStats\")\n",
        "import Pkg; Pkg.add(\"Plots\")\n",
        "import Pkg; Pkg.add(\"NCDatasets\")\n",
        "import Pkg; Pkg.add(\"StatsBase\")\n",
        "import Pkg; Pkg.add(\"Unitful\")\n",
        "import Pkg; Pkg.add(\"DataFrames\")\n",
        "import Pkg; Pkg.add(\"DecisionTree\")"
      ],
      "id": "f71c1f12",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "using Dates\n",
        "using MultivariateStats\n",
        "using Plots\n",
        "using NCDatasets\n",
        "using StatsBase\n",
        "using Unitful\n",
        "using DataFrames\n",
        "using DecisionTree\n",
        "Plots.default(; margin=4Plots.mm, size=(700, 400), linewidth=2)"
      ],
      "id": "ca51e4a6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Loading in Datasets\n",
        "### 2.1. Precipitation Data\n",
        "I first loaded in my precipitation dataset using NCDataset, and then made variables precip_time, precip_lon, precip_lat, and precip that represent the time, coordinates, and precipitation at a given coordinate at a given time between January 1, 2010 and December 31 of 2020.\n"
      ],
      "id": "486ab20a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "precip_ds = NCDataset(\"data/raw/precip_tx.nc\") #loading in the precip_tx.nc dataset"
      ],
      "id": "1e77363f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Here, I'm creating variables from the precip_tx.nc dataset.\n",
        "precip_time = precip_ds[\"time\"][11324:15341] #saving the time data from 2010 through 2020\n",
        "precip_time = Date.(precip_time)\n",
        "precip_lon = precip_ds[\"lon\"][:]\n",
        "precip_lat = precip_ds[\"lat\"][:]\n",
        "precip_lat = reverse(precip_lat) #The latitude needs to be reversed.\n",
        "precip = (precip_ds[\"precip\"][:, :,11324:15341])*.1u\"mm\" #this precipitation data is in millimeters, so I'm adding in units.\n",
        "precip = reverse(precip, dims=2) #Because we reversed the latitude, we need to do the same in the second dimension of the precipitation data."
      ],
      "id": "7dc1df81",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "display(precip_ds[:precip])"
      ],
      "id": "2efc60f0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "close(precip_ds) #closing the dataset"
      ],
      "id": "d7d093fa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "heatmap(precip_lon, precip_lat, precip[:,:,1]';xlabel=\"Longitude\", ylabel=\"Latitude\", title=\"Preipitation on $(precip_time[1])\")"
      ],
      "id": "69235bd1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Temperature Data\n",
        "\n",
        "#### Loading in Temperature Data Year by Year\n",
        "Next, I loaded in each temperature dataset from 2010 through 2020 individually, giving each dataset it's own time, lon, lat, and temp data.\n"
      ],
      "id": "52e203ee"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "temp10_ds = NCDataset(\"data/raw/2m_temperature_2010.nc\") "
      ],
      "id": "5a2fc506",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Here, I'm creating variables from the 2m_temperature_2010.nc dataset.\n",
        "temp10_time = temp10_ds[\"time\"]\n",
        "temp10_time = Date.(temp10_time)\n",
        "temp10_lon = temp10_ds[\"longitude\"][:]\n",
        "temp10_lat = temp10_ds[\"latitude\"][:]\n",
        "temp10_lat = reverse(temp10_lat) #The latitude needs to be reversed.\n",
        "temp10 = (temp10_ds[\"t2m\"][:, :,:])*.1u\"K\" #this temp data is in Kelvin, so I'm adding in units.\n",
        "temp10 = reverse(temp10, dims=2) #Because we reversed the latitude, we need to do the same in the second dimension of the temperature data."
      ],
      "id": "32c84e1a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "close(temp10_ds)"
      ],
      "id": "7c95a3ad",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Repeating each step for temp datasets from 2011 to 2020\n"
      ],
      "id": "a0b18e98"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "temp11_ds = NCDataset(\"data/raw/2m_temperature_2011.nc\") "
      ],
      "id": "8d9dec8d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "temp11_time = temp11_ds[\"time\"]\n",
        "temp11_time = Date.(temp11_time)\n",
        "temp11_lon = temp11_ds[\"longitude\"][:]\n",
        "temp11_lat = temp11_ds[\"latitude\"][:]\n",
        "temp11_lat = reverse(temp11_lat) \n",
        "temp11 = (temp11_ds[\"t2m\"][:, :,:])*.1u\"K\" \n",
        "temp11 = reverse(temp11, dims=2)"
      ],
      "id": "c4faf1c5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "close(temp11_ds)"
      ],
      "id": "73ed1744",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "temp12_ds = NCDataset(\"data/raw/2m_temperature_2012.nc\") "
      ],
      "id": "f014929a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "temp12_time = temp12_ds[\"time\"]\n",
        "temp12_time = Date.(temp12_time)\n",
        "temp12_lon = temp12_ds[\"longitude\"][:]\n",
        "temp12_lat = temp12_ds[\"latitude\"][:]\n",
        "temp12_lat = reverse(temp12_lat) \n",
        "temp12 = (temp12_ds[\"t2m\"][:, :,:])*.1u\"K\" \n",
        "temp12 = reverse(temp12, dims=2) "
      ],
      "id": "af7229f5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "close(temp12_ds)"
      ],
      "id": "3dd4f289",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "temp13_ds = NCDataset(\"data/raw/2m_temperature_2013.nc\") "
      ],
      "id": "a67ebcae",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "temp13_time = temp13_ds[\"time\"]\n",
        "temp13_time = Date.(temp13_time)\n",
        "temp13_lon = temp13_ds[\"longitude\"][:]\n",
        "temp13_lat = temp13_ds[\"latitude\"][:]\n",
        "temp13_lat = reverse(temp13_lat)\n",
        "temp13 = (temp13_ds[\"t2m\"][:, :,:])*.1u\"K\" \n",
        "temp13 = reverse(temp13, dims=2)"
      ],
      "id": "210b9673",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "close(temp13_ds)"
      ],
      "id": "7688c3f0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "temp14_ds = NCDataset(\"data/raw/2m_temperature_2014.nc\") "
      ],
      "id": "c5ac85bf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "temp14_time = temp14_ds[\"time\"]\n",
        "temp14_time = Date.(temp14_time)\n",
        "temp14_lon = temp14_ds[\"longitude\"][:]\n",
        "temp14_lat = temp14_ds[\"latitude\"][:]\n",
        "temp14_lat = reverse(temp14_lat) \n",
        "temp14 = (temp14_ds[\"t2m\"][:, :,:])*.1u\"K\" \n",
        "temp14 = reverse(temp14, dims=2) "
      ],
      "id": "c8a85828",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "close(temp14_ds)"
      ],
      "id": "e3d4b553",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "temp15_ds = NCDataset(\"data/raw/2m_temperature_2015.nc\") "
      ],
      "id": "63d58030",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "temp15_time = temp15_ds[\"time\"]\n",
        "temp15_time = Date.(temp15_time)\n",
        "temp15_lon = temp15_ds[\"longitude\"][:]\n",
        "temp15_lat = temp15_ds[\"latitude\"][:]\n",
        "temp15_lat = reverse(temp15_lat) \n",
        "temp15 = (temp15_ds[\"t2m\"][:, :,:])*.1u\"K\" \n",
        "temp15 = reverse(temp15, dims=2) "
      ],
      "id": "a664d18c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "close(temp15_ds)"
      ],
      "id": "8d03a559",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "temp16_ds = NCDataset(\"data/raw/2m_temperature_2016.nc\") "
      ],
      "id": "cd8cee79",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "temp16_time = temp16_ds[\"time\"]\n",
        "temp16_time = Date.(temp16_time)\n",
        "temp16_lon = temp16_ds[\"longitude\"][:]\n",
        "temp16_lat = temp16_ds[\"latitude\"][:]\n",
        "temp16_lat = reverse(temp16_lat) \n",
        "temp16 = (temp16_ds[\"t2m\"][:, :,:])*.1u\"K\" \n",
        "temp16 = reverse(temp16, dims=2) "
      ],
      "id": "9ade22ff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "close(temp16_ds)"
      ],
      "id": "96f8a622",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "temp17_ds = NCDataset(\"data/raw/2m_temperature_2017.nc\") "
      ],
      "id": "d5a4a2a2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "temp17_time = temp17_ds[\"time\"]\n",
        "temp17_time = Date.(temp17_time)\n",
        "temp17_lon = temp17_ds[\"longitude\"][:]\n",
        "temp17_lat = temp17_ds[\"latitude\"][:]\n",
        "temp17_lat = reverse(temp17_lat) \n",
        "temp17 = (temp17_ds[\"t2m\"][:, :,:])*.1u\"K\" \n",
        "temp17 = reverse(temp17, dims=2)"
      ],
      "id": "eb515765",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "close(temp17_ds)"
      ],
      "id": "b3b14d6b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "temp18_ds = NCDataset(\"data/raw/2m_temperature_2018.nc\") "
      ],
      "id": "5c712e87",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "temp18_time = temp18_ds[\"time\"]\n",
        "temp18_time = Date.(temp18_time)\n",
        "temp18_lon = temp18_ds[\"longitude\"][:]\n",
        "temp18_lat = temp18_ds[\"latitude\"][:]\n",
        "temp18_lat = reverse(temp18_lat) \n",
        "temp18 = (temp18_ds[\"t2m\"][:, :,:])*.1u\"K\" \n",
        "temp18 = reverse(temp18, dims=2)"
      ],
      "id": "7bf5a9dc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "close(temp18_ds)"
      ],
      "id": "b59ce5d9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "temp19_ds = NCDataset(\"data/raw/2m_temperature_2019.nc\") "
      ],
      "id": "212c2689",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "temp19_time = temp19_ds[\"time\"]\n",
        "temp19_time = Date.(temp19_time)\n",
        "temp19_lon = temp19_ds[\"longitude\"][:]\n",
        "temp19_lat = temp19_ds[\"latitude\"][:]\n",
        "temp19_lat = reverse(temp19_lat)\n",
        "temp19 = (temp19_ds[\"t2m\"][:, :,:])*.1u\"K\" \n",
        "temp19 = reverse(temp19, dims=2)"
      ],
      "id": "5dcbbc88",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "close(temp19_ds)"
      ],
      "id": "8552f309",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "temp20_ds = NCDataset(\"data/raw/2m_temperature_2020.nc\") "
      ],
      "id": "1f46a686",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "temp20_time = temp20_ds[\"time\"]\n",
        "temp20_time = Date.(temp20_time)\n",
        "temp20_lon = temp20_ds[\"longitude\"][:]\n",
        "temp20_lat = temp20_ds[\"latitude\"][:]\n",
        "temp20_lat = reverse(temp20_lat) \n",
        "temp20 = (temp20_ds[\"t2m\"][:, :,:])*.1u\"K\" \n",
        "temp20 = reverse(temp20, dims=2)"
      ],
      "id": "bb224555",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "close(temp20_ds)"
      ],
      "id": "9f383fa9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Creating One Large Dataset That Combines all Temp Dat & Converting Times to Daily Instead of Hourly\n",
        "After loading in the temperature data from each year from 2010 through 2020, I then aggregated all of the time and temperature data into 2 large variables called temp and temp_time.\n"
      ],
      "id": "4a764265"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Function to read temperature data for a given year\n",
        "function read_temperature_data(year)\n",
        "    ds = NCDataset(\"data/raw/2m_temperature_$(year).nc\")\n",
        "    \n",
        "    time = Date.(ds[\"time\"])\n",
        "    lon = ds[\"longitude\"][:]\n",
        "    lat = reverse(ds[\"latitude\"][:])\n",
        "    temp = (ds[\"t2m\"][:, :, :]) * 0.1u\"K\"\n",
        "    temp = reverse(temp, dims=2)\n",
        "    \n",
        "    close(ds)\n",
        "    \n",
        "    return time, lon, lat, temp\n",
        "end\n",
        "\n",
        "# Function to aggregate hourly data to daily data\n",
        "function aggregate_to_daily(time, temp)\n",
        "    unique_dates = unique(time)\n",
        "    daily_temp = []\n",
        "\n",
        "    for date in unique_dates\n",
        "        indices = findall(x -> x == date, time)\n",
        "        daily_mean = mean(temp[:, :, indices], dims=3)\n",
        "        push!(daily_temp, daily_mean)\n",
        "    end\n",
        "\n",
        "    return unique_dates, cat(daily_temp..., dims=3)\n",
        "end\n",
        "\n",
        "# Years to process\n",
        "years = 2010:2020\n",
        "\n",
        "# Initialize arrays to store aggregated data\n",
        "all_aggregated_times = []\n",
        "all_aggregated_temps = []\n",
        "\n",
        "# Loop over years and read/aggregate data\n",
        "for year in years\n",
        "    time, _, _, temp = read_temperature_data(year)\n",
        "    aggregated_times, aggregated_temp = aggregate_to_daily(time, temp)\n",
        "    \n",
        "    push!(all_aggregated_times, aggregated_times)\n",
        "    push!(all_aggregated_temps, aggregated_temp)\n",
        "end\n",
        "\n",
        "# Combine aggregated data\n",
        "combined_aggregated_times = cat(all_aggregated_times..., dims=1)\n",
        "combined_aggregated_temps = cat(all_aggregated_temps..., dims=3)"
      ],
      "id": "72aadf2a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "temp_lat = temp10_lat[1:14] #All of the lat data from the different temp datasets are the same, so I represent the lat for the whole temp data just as one of lat variables I made earlier\n",
        "temp_lon = temp10_lon[30:41] #All of the lon data from the different temp datasets are the same, so I represent the lon for the whole temp data just as one of lon variables I made earlier\n",
        "temp_time = combined_aggregated_times\n",
        "temp = combined_aggregated_temps[30:41,1:14,:]"
      ],
      "id": "720321c0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::{.callout-note}\n",
        "I'm also matching the latitude and longitude ranges of the temperature data to match with the precipitation data here. \n",
        ":::\n"
      ],
      "id": "528dd0c3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "@assert temp_time == precip_time #Making sure that my two time variables are the same"
      ],
      "id": "f106875e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "heatmap(temp_lon, temp_lat, temp[:,:,1]'; xlabel=\"Longitude\", ylabel=\"Latitude\", title=\"Temperature on $(temp_time[1])\")"
      ],
      "id": "fbf37fb9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Splitting Data into Testing & Training data\n",
        "I then split my data into test and training data, with 70% being training data, and 30% being test data.\n"
      ],
      "id": "0496e631"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "test_start_date = Date(2017, 09, 13) #Splitting the test and training data 70%-30%\n",
        "test_start_index = searchsortedfirst(temp_time, test_start_date)"
      ],
      "id": "8c7611f3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Here I'm splitting my data into training & testing sets\n",
        "\n",
        "precip_train = precip[:, :, 1:test_start_index - 1]\n",
        "precip_test = precip[:, :, test_start_index:end]\n",
        "\n",
        "temp_train = temp[:, :, 1:test_start_index - 1]\n",
        "temp_test = temp[:, :, test_start_index:end]\n",
        "\n",
        "time_train = temp_time[1:test_start_index - 1]\n",
        "time_test = temp_time[test_start_index:end]"
      ],
      "id": "a2695007",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Preprocessing\n",
        "I then preprocessed my temperature data to get information about the variance and reshape it for use in PCA analysis.\n"
      ],
      "id": "2ef0074c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Preprocessing the data here to get data about the variance and reshape the variance data so it can be used for PCA\n",
        "function preprocess(temp::Array{T,3}, temp_reference::Array{T,3})::AbstractMatrix where {T}\n",
        "    n_lon, n_lat, n_time = size(temp)\n",
        "    climatology = mean(temp_reference; dims=3)\n",
        "    temp_anom = temp .- climatology\n",
        "\n",
        "    #reshape to 2D\n",
        "    temp_anom = reshape(temp_anom, n_lon * n_lat, n_time)\n",
        "\n",
        "    #stripping units\n",
        "    return ustrip.(u\"K\", temp_anom)\n",
        "end"
      ],
      "id": "83619045",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "n_lon, n_lat, n_time = size(temp)\n",
        "\n",
        "temp_mat_train = preprocess(temp_train, temp_train)\n",
        "temp_mat_test = preprocess(temp_test, temp_train)"
      ],
      "id": "a21ba77a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Methods \n",
        "\n",
        "## 1. Principal Components\n",
        "I then ran principal components analysis on the temperature training data through fitting the training data to PCA and plotting the variance and cumulative variance.\n",
        "### 1.1 Fitting\n"
      ],
      "id": "3e71c574"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pca_model = fit(PCA, temp_mat_train; maxoutdim=10, pratio=0.99);\n",
        "pca_model"
      ],
      "id": "aedf6c4a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "p1 = plot(principalvars(pca_model)/var(pca_model); xlabel=\"# of PC's\", xticks= [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], ylabel= \"Fraction of Variance Explained\", label = false, title= \"Variance Explained\")\n",
        "\n",
        "p2 = plot(cumsum(principalvars(pca_model))/var(pca_model); xlabel=\"# of PC's\", xticks= [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], ylabel= \"Fraction of Variance Explained\", label = false, title= \"Cumulative Variance Explained\")\n",
        "\n",
        "plot(p1,p2; layout=(1,2), size=(900,400))"
      ],
      "id": "ed504cd5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After looking at the cumulative variance explained plot, I decided to use 3 principal components because those three account for almost 0.95 of the cumulative variance, but reduces alot of the noise.\n"
      ],
      "id": "fb3682f3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "p = []\n",
        "for i in 1:3\n",
        "    pc = projection(pca_model)[:, i]\n",
        "    pc_reshape = reshape(pc, n_lon, n_lat)'\n",
        "    pi = heatmap(\n",
        "        temp_lon,\n",
        "        temp_lat,\n",
        "        pc_reshape;\n",
        "        xlabel=\"Longitude\",\n",
        "        ylabel=\"Latitude\",\n",
        "        title=\"PC $i\",\n",
        "        aspect_ratio=:equal,\n",
        "        cmap=:PuOr\n",
        "    )\n",
        "    push!(p, pi)\n",
        "end\n",
        "plot(p...; layout=(1, 3), size=(1800, 600))"
      ],
      "id": "fbf731f2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pc_ts = StatsBase.predict(pca_model, temp_mat_train)\n",
        "day_of_year = Dates.dayofyear.(temp_time)\n",
        "\n",
        "p = []\n",
        "for i in 1:3\n",
        "    pi = scatter(\n",
        "        day_of_year,\n",
        "        pc_ts[i, :];\n",
        "        xlabel=\"Day of Year\",\n",
        "        ylabel=\"PC $i\",\n",
        "        title=\"PC $i\",\n",
        "        label=false,\n",
        "        alpha=0.3,\n",
        "        color=:gray\n",
        "    )\n",
        "    push!(p, pi)\n",
        "end\n",
        "plot(p...; layout=(1, 3), size=(1800, 600))"
      ],
      "id": "45af5c1d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From this plot, we see that principal components 1 & 2 appear to have some sort of relation to the difference in temperatures on land and in the ocean, while the third prinicipal component appears to have some sort of relation to longitude.\n"
      ],
      "id": "150519d7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Months = Dates.month.(temp_time)\n",
        "\n",
        "p=[]\n",
        "for i in 1:3\n",
        "    pi=scatter(\n",
        "        Months,\n",
        "        pc_ts[i, :];\n",
        "        xlabel= \"Months in a Year\",\n",
        "        ylabel = \"PC $i\",\n",
        "        title = \"PC $i\",\n",
        "        label = false,\n",
        "        alpha= 0.3,\n",
        "        color=:blue,\n",
        "        xticks =[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
        "    )\n",
        "    push!(p, pi)\n",
        "end\n",
        "plot(p...; layout=(1,3), size=(1800, 600))    "
      ],
      "id": "691778f3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From this plot, we can see that principal component 1 is definitely driving the seasonal cycle of the data, principal components 2 and 3 appear more closesly related with daily variances in temperature.\n"
      ],
      "id": "10f1f5e1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "avg_precip = ustrip.(u\"mm\", [mean(skipmissing(precip_train[:, :, t])) for t in 1:size(precip_train, 3)])\n",
        "avg_precip = replace(avg_precip, NaN => 0)"
      ],
      "id": "8d5040a7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "p1 = scatter(\n",
        "    pc_ts[2, :],\n",
        "    pc_ts[3, :];\n",
        "    zcolor=avg_precip,\n",
        "    xlabel=\"PC 2\",\n",
        "    ylabel=\"PC 3\",\n",
        "    markersize=3,\n",
        "    clims=(0, 2.75),\n",
        "    title=\"All Days\",\n",
        "    label=false\n",
        ")\n",
        "\n",
        "p2_idx = findall(avg_precip .> quantile(avg_precip, 0.98))\n",
        "p2 = scatter(\n",
        "    pc_ts[2, p2_idx],\n",
        "    pc_ts[3, p2_idx];\n",
        "    zcolor=avg_precip[p2_idx],\n",
        "    xlabel=\"PC 2\",\n",
        "    ylabel=\"PC 3\",\n",
        "    markersize=5,\n",
        "    clims=(0, 2.75),\n",
        "    title=\"Rainy Days\",\n",
        "    label=false\n",
        ")\n",
        "plot(p1, p2; size=(1800, 600), link=:both)"
      ],
      "id": "547a0edc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. K-NN Model\n"
      ],
      "id": "04cde20e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "function euclidean_distance(x::AbstractVector, y::AbstractVector)::AbstractFloat\n",
        "    return sqrt(sum((x .- y) .^ 2))\n",
        "end\n",
        "function nsmallest(x::AbstractVector, n::Int)::Vector{Int}\n",
        "    idx = sortperm(x)\n",
        "    return idx[1:n]\n",
        "end\n",
        "function knn(X::AbstractMatrix, X_i::AbstractVector, K::Int)::Tuple{Int,AbstractVector}\n",
        "    # calculate the distances between X_i and each row of X\n",
        "    dist = [euclidean_distance(X_i, X[j, :]) for j in 1:size(X, 1)]\n",
        "    idx = nsmallest(dist, K)\n",
        "    w = 1 ./ dist[idx]\n",
        "    w ./= sum(w)\n",
        "    idx_sample = sample(idx, Weights(w))\n",
        "    return (idx_sample, vec(X[idx_sample, :]))\n",
        "end"
      ],
      "id": "255ec7c4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "function predict_knn(temp_train, temp_test, precip_train; n_pca::Int)\n",
        "    X_train = preprocess(temp_train, temp_train)\n",
        "    X_test = preprocess(temp_test, temp_train)\n",
        "\n",
        "    # fit the PCA model to the training data\n",
        "    pca_model = fit(PCA, X_train; maxoutdim=n_pca)\n",
        "\n",
        "    # project the test data onto the PCA basis\n",
        "    train_embedded = StatsBase.predict(pca_model, X_train)\n",
        "    test_embedded = StatsBase.predict(pca_model, X_test)\n",
        "\n",
        "    # use the `knn` function for each point in the test data\n",
        "    precip_pred = map(1:size(X_test, 2)) do i\n",
        "        idx, _ = knn(train_embedded', test_embedded[:, i], 3)\n",
        "        precip_train[:, :, idx]\n",
        "    end\n",
        "# return a matrix of predictions\n",
        "    return precip_pred\n",
        "end"
      ],
      "id": "48a10e10",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "t_sample = rand(1:size(temp_test, 3), 3)\n",
        "precip_pred = predict_knn(temp_train, temp_test[:, :, t_sample], precip_train; n_pca=3)"
      ],
      "id": "a8951d24",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "p = map(eachindex(t_sample)) do ti\n",
        "    t = t_sample[ti]\n",
        "    y_pred = precip_pred[ti]'\n",
        "    y_actual = precip_test[:, :, t]'\n",
        "    cmax = max(maximum(skipmissing(y_pred)), maximum(skipmissing(y_actual)))\n",
        "    cmax = ustrip(u\"mm\", cmax)\n",
        "\n",
        "    p1 = heatmap(\n",
        "        precip_lon,\n",
        "        precip_lat,\n",
        "        y_pred;\n",
        "        xlabel=\"Longitude\",\n",
        "        ylabel=\"Latitude\",\n",
        "        title=\"Predicted\",\n",
        "        aspect_ratio=:equal,\n",
        "        clims=(0, cmax)\n",
        "    )\n",
        "\n",
        "    p2 = heatmap(\n",
        "        precip_lon,\n",
        "        precip_lat,\n",
        "        y_actual;\n",
        "        xlabel=\"Longitude\",\n",
        "        ylabel=\"Latitude\",\n",
        "        title=\"Actual\",\n",
        "        aspect_ratio=:equal,\n",
        "        clims=(0, cmax)\n",
        "    )\n",
        "\n",
        "    plot(p1, p2; layout=(2, 1), size=(1000, 400))\n",
        "end\n",
        "plot(p...; layout=(2, 3), size=(1500, 1200))"
      ],
      "id": "5df3587f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Random Forest Model\n"
      ],
      "id": "cae6e7a7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "function train_random_forest(temp_train, temp_test::Any, precip_train::Any; n_pca::Int, n_trees::Int)\n",
        "    X_train = preprocess(temp_train, temp_train)\n",
        "    X_test = preprocess(temp_test, temp_train)\n",
        "    \n",
        "    PCA_model = fit(PCA, X_train, maxoutdim=n_pca)\n",
        "\n",
        "    y_train = avg_precip\n",
        "\n",
        "    # Flatten to 2D arrays\n",
        "    train_embedded = StatsBase.predict(PCA_model, X_train)\n",
        "    test_embedded = StatsBase.predict(PCA_model, X_test)\n",
        "\n",
        "    y_train_no_missing = avg_precip[.!ismissing.(avg_precip)]\n",
        "\n",
        "\n",
        "    # Train the Random Forest model\n",
        "    rf_model = DecisionTree.build_forest(\n",
        "        y_train_no_missing,\n",
        "        train_embedded[:, :, findall(!ismissing, y_train)],\n",
        "        n_trees\n",
        "    )\n",
        "    \n",
        "    return rf_model\n",
        "end"
      ],
      "id": "09fe4cd5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "rf_model = train_random_forest(temp_train, temp_test, precip_train; n_pca=3, n_trees=100)"
      ],
      "id": "9a516177",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Comparison\n",
        "I tried to create a random forest model in order to make a comparison about which model worked best for my data, but couldn't get my code for the random forest model to work. However, I do believe that my random forest model, if using the original data and not the PCA data, could have been better for my large dataset. I think a big reason my KNN model didn't do great was because there was still some noise from outliers even after choosing my principal components. Because KNN models are sensitive to noise, that noise may have caused my model to struggle.\n",
        "\n",
        "# Conclusion\n",
        "I think that overall, while my KNN model didn't work great and I couldn't get a second model to run, this project wasn't a complete failure. I think that even though I didn't get the results I wanted, I ended up deepening my understanding of PCA, KNN models, and random forest models hrough the process of trying to put this project together."
      ],
      "id": "ce1e9667"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "julia-1.9",
      "language": "julia",
      "display_name": "Julia 1.9.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}