---
title: "Lab 06"
subtitle: "$K$NN and PCA"
jupyter: julia-1.9
date: 2023-10-13
author: Riley Becker (rb111)
---

# 1. Intro
```{julia}
import Pkg; Pkg.add("MultivariateStats")
import Pkg; Pkg.add("Plots")
import Pkg; Pkg.add("NCDatasets")
import Pkg; Pkg.add("StatsBase")
import Pkg; Pkg.add("Unitful")
```
```{julia}
import Pkg; Pkg.add("DataFrames")
```
```{julia}
using Dates
using MultivariateStats
using Plots
using NCDatasets
using StatsBase
using Unitful
using DataFrames
Plots.default(; margin=4Plots.mm, size=(700, 400), linewidth=2)
```

# 2. Data
## 2a. Precipitation Data
```{julia}
precip_ds = NCDataset("data/raw/precip_tx.nc") #loading in the precip_tx.nc dataset
```
```{julia}
# Here, I'm creating variables from the precip_tx.nc dataset.
precip_time = precip_ds["time"][:]
precip_time = Date.(precip_time)
precip_lon = precip_ds["lon"][:]
precip_lat = precip_ds["lat"][:]
precip_lat = reverse(precip_lat) #The latitude needs to be reversed.
precip = (precip_ds["precip"][:, :, :])*.1u"mm" #this precipitation data is in millimeters, so I'm adding in units.
precip = reverse(precip, dims=2) #Because we reversed the latitude, we need to do the same in the second dimension of the precipitation data.
```
```{julia}
close(precip_ds) #closing the dataset
```

## 2b. Temperature Data
### Loading in Temperature Data
```{julia}
function open_mfdataset(files::Vector{String}, variable_name::AbstractString)
    # Lists to store variable data, time data, and other coordinate data
    var_data_list = []
    time_data_list = []
    coords_data_dict = Dict()

    # Open the first file to get the coordinate names (excluding time and the main variable)
    ds = Dataset(files[1])
    dimnames = keys(ds.dim)
    coord_names = setdiff(collect(dimnames), [variable_name, "time"])
    close(ds)

    # Initialize lists for each coordinate in coords_data_dict
    for coord in coord_names
        coords_data_dict[coord] = []
    end

    # Open each file, extract data, and store in lists
    for file in files
        ds = Dataset(file)

        # Store variable and time data
        push!(var_data_list, ds[variable_name][:])
        push!(time_data_list, ds["time"][:])

        # Store other coordinate data
        for coord in coord_names
            push!(coords_data_dict[coord], ds[coord][:])
        end

        close(ds)
    end

    # Pair variable data with time data and sort by time
    sorted_pairs = sort(collect(zip(time_data_list, var_data_list)); by=x -> x[1])
    sorted_time_data = [pair[1] for pair in sorted_pairs]
    sorted_var_data = [pair[2] for pair in sorted_pairs]

    # Concatenate sorted data
    concatenated_data_dict = Dict(
        variable_name => vcat(sorted_var_data...), "time" => vcat(sorted_time_data...)
    )

    # Concatenate coordinate data and add to the dictionary
    for coord in coord_names
        concatenated_data_dict[coord] = vcat(coords_data_dict[coord]...)
    end

    return concatenated_data_dict
end

function glob(pattern::AbstractString, dir::AbstractString=".")
    # Convert the glob-like pattern to a regex pattern
    regex_pattern = replace(pattern, "*" => ".*")
    regex_pattern = Regex(regex_pattern)

    # List all files in the directory and filter by the regex pattern
    matching_files = filter(
        filename -> occursin(regex_pattern, filename), readdir(dir; join=true)
    )

    return matching_files
end

function run_demo()
    global t2m
    # the path to the raw data folder
    data_dir = joinpath(HOMEDIR, "data", "raw")
    years = 1979:2023 # example time range
    for year in years
        # Download 2m air temperature for the year 2020
        download_single_level_data.(
            year, joinpath(data_dir, "2m_temperature_$year.nc"), "2m_temperature"
        )        
    end
    # read in all the 2m temperature data
    fnames = shuffle(glob("2m_temperature", data_dir)) # shuffle -- should work even if out of order
    t2m = open_mfdataset(fnames, "t2m") # we sort based on time, so we don't need to sort here
    
    return t2m
end
```

### Temperature Variables
```{julia}
# ADD IN NOTES HERE
temp_time = t2m["time"]
temp_time = temp_time[1:392737]
temp_time = hcat(temp_time)
```

```{julia}
temp_lon = t2m["longitude"]
temp_lon = hcat(temp_lon)
```
```{julia}
temp_lon_unique = unique(temp_lon)
```
```{julia}
temp_lat = t2m["latitude"] #Just like precip_lat, temp_lat also needs to be reversed.
temp_lat = reverse(temp_lat)
temp_lat = hcat(temp_lat)
```
```{julia}
temp_lat_unique = unique(temp_lat)
```
```{julia}
temp = reduce(hcat, t2m["t2m"])
```

lat_len = length(temp_lat_unique)
lon_len = length(temp_lon_unique)
time_len = length(temp_time)

temp = reshape(temp, lat_len, lon_len, time_len)
```


```{julia}
#INSERT FUNCTION THAT MAKES TEMP AND PRECIP TIME THE SAME
temp_date = Date.(temp_time)
temp_date = unique(temp_date)
```
```{julia}
@assert temp_date == precip_time
```
```{julia}
time = Date.(precip_time)
```
```julia
# Here I'm reshaping the t2m dictionary (from get_data.jl) into a matrix
# Extract t2m values
temp = t2m["t2m"]

# Assuming the other vectors are consistent in length
rows = length(t2m["time"])
cols = length(t2m["latitude"]) * length(t2m["longitude"])

# Reshape t2m into a matrix
temp_matrix = reshape(t2m, rows, cols)
```

# 3. Splitting Data
```{julia}
#ADD IN NOTES HERE
test_start_date = Date(2011, 1, 1) #CHANGE THIS
test_start_index = searchsortedfirst(time, test_start_date)
```
```{julia}
# Here I'm splitting my data into training & testing sets

precip_train = precip[:, :, 1:test_start_index - 1]

precip_test = precip[:, :, test_start_index:end]
```
```{julia}
temp_train = temp[:, :, 1:test_start_index - 1]

temp_test = temp[:, :, test_start_index:end]
```
```{julia}
time_train = time[1:test_start_index - 1]
time_test = time[test_start_index:end]
```

# 4. Preprocessing
```{julia}

# ADD IN EXPLANATION AS TO WHAT IM PREPROCESSING & WHY
