---
title: "Project 1"
subtitle: Precipitation Downscaling
jupyter: julia-1.9
date: 2023-11-13
author: Riley Becker (rb111)
---

# 1. Intro
```{julia}
import Pkg; Pkg.add("MultivariateStats")
import Pkg; Pkg.add("Plots")
import Pkg; Pkg.add("NCDatasets")
import Pkg; Pkg.add("StatsBase")
import Pkg; Pkg.add("Unitful")
```
```{julia}
import Pkg; Pkg.add("DataFrames")
```
```{julia}
using Dates
using MultivariateStats
using Plots
using NCDatasets
using StatsBase
using Unitful
using DataFrames
Plots.default(; margin=4Plots.mm, size=(700, 400), linewidth=2)
```

# 2. Data
## 2a. Precipitation Data
```{julia}
precip_ds = NCDataset("data/raw/precip_tx.nc") #loading in the precip_tx.nc dataset
```
```{julia}
# Here, I'm creating variables from the precip_tx.nc dataset.
precip_time = precip_ds["time"][732:end]
precip_time = Date.(precip_time)
precip_lon = precip_ds["lon"][:]
precip_lat = precip_ds["lat"][:]
precip_lat = reverse(precip_lat) #The latitude needs to be reversed.
precip = (precip_ds["precip"][:, :, 732:end])*.1u"mm" #this precipitation data is in millimeters, so I'm adding in units.
precip = reverse(precip, dims=2) #Because we reversed the latitude, we need to do the same in the second dimension of the precipitation data.
```
```{julia}
close(precip_ds) #closing the dataset
```

```{julia}
close(temp_ds)
```
## 2b. Temperature Data
### Loading in Temperature Data
```{julia}
function open_mfdataset(files::Vector{String}, variable_name::AbstractString)
    # Lists to store variable data, time data, and other coordinate data
    var_data_list = []
    time_data_list = []
    coords_data_dict = Dict()

    # Open the first file to get the coordinate names (excluding time and the main variable)
    ds = Dataset(files[1])
    dimnames = keys(ds.dim)
    coord_names = setdiff(collect(dimnames), [variable_name, "time"])
    close(ds)

    # Initialize lists for each coordinate in coords_data_dict
    for coord in coord_names
        coords_data_dict[coord] = []
    end

    # Open each file, extract data, and store in lists
    for file in files
        ds = Dataset(file)

        # Store variable and time data
        push!(var_data_list, ds[variable_name][:])
        push!(time_data_list, ds["time"][:])

        # Store other coordinate data
        for coord in coord_names
            push!(coords_data_dict[coord], ds[coord][:])
        end

        close(ds)
    end

    # Pair variable data with time data and sort by time
    sorted_pairs = sort(collect(zip(time_data_list, var_data_list)); by=x -> x[1])
    sorted_time_data = [pair[1] for pair in sorted_pairs]
    sorted_var_data = [pair[2] for pair in sorted_pairs]

    # Concatenate sorted data
    concatenated_data_dict = Dict(
        variable_name => vcat(sorted_var_data...), "time" => vcat(sorted_time_data...)
    )

    # Concatenate coordinate data and add to the dictionary
    for coord in coord_names
        concatenated_data_dict[coord] = vcat(coords_data_dict[coord]...)
    end

    return concatenated_data_dict
end
```



```{julia}
using CDSAPI
base_path = "data/raw"
files = ["2m_temperature_1979.nc","2m_temperature_1980.nc","2m_temperature_1981.nc","2m_temperature_1982.nc","2m_temperature_1983.nc","2m_temperature_1984.nc", "2m_temperature_1985.nc","2m_temperature_1986.nc", "2m_temperature_1987.nc", "2m_temperature_1988.nc", "2m_temperature_1989.nc", "2m_temperature_1990.nc", "2m_temperature_1991.nc", "2m_temperature_1992.nc","2m_temperature_1993.nc","2m_temperature_1994.nc","2m_temperature_1995.nc","2m_temperature_1996.nc","2m_temperature_1997.nc","2m_temperature_1998.nc","2m_temperature_1999.nc","2m_temperature_2000.nc","2m_temperature_2001.nc","2m_temperature_2002.nc","2m_temperature_2003.nc","2m_temperature_2004.nc","2m_temperature_2005.nc","2m_temperature_2006.nc","2m_temperature_2007.nc","2m_temperature_2008.nc","2m_temperature_2009.nc","2m_temperature_2010.nc","2m_temperature_2011.nc","2m_temperature_2012.nc","2m_temperature_2013.nc","2m_temperature_2014.nc","2m_temperature_2015.nc","2m_temperature_2016.nc","2m_temperature_2017.nc","2m_temperature_2018.nc","2m_temperature_2019.nc","2m_temperature_2020.nc","2m_temperature_2021.nc","2m_temperature_2022.nc", "2m_temperature_2023.nc"]
```
```{julia}
file_paths = [joinpath(base_path, file) for file in files]
```
```{julia}
t2m = open_mfdataset(file_paths, "t2m")
```



### Temperature Variables

```{julia}
start_date = Date(t2m["time"][1])
end_date = Date(t2m["time"][end])

println(start_date)
println(end_date)

# Calculate the number of days between the two dates
num_days = (end_date) - (start_date) 
num_days = Dates.value(num_days) + 1
num_years = (Dates.year(end_date) - Dates.year(start_date)) + 1

println("Number of days from $(Dates.year(start_date)) to $(Dates.year(end_date)): $num_days and $num_years years" )

n_lon = Int(length(t2m["longitude"])/(num_years))
n_lat = Int(length(t2m["latitude"])/(num_years))

temp_long = t2m["longitude"][1:n_lon]
temp_lat = t2m["latitude"][1:n_lat]

println("n_lon = $n_lon ")
println("n_lat = $n_lat ")

data_dict_temp = reshape(t2m["t2m"], (n_lon,n_lat,num_days*24))

```
```{julia}
#Creating a function that transforms time & temperature to daily instead of hourly
function hourly_to_daily(hourly_data, timestamps)
    daily_data = Union{Missing, Float64}[]
    unique_dates = unique(Dates.Date.(timestamps))
    
    for date in unique_dates
        indices = findall(x -> Dates.Date(x) == date, timestamps)
        daily_value = mean(hourly_data[indices])
        push!(daily_data, daily_value)
    end
    
    return daily_data, unique_dates
end

# Assuming "t2m" is the hourly temperature data, and "time" is the corresponding timestamps
hourly_temperature = t2m["t2m"]
timestamps = t2m["time"]

daily_temperature, daily_dates = hourly_to_daily(hourly_temperature, timestamps)

# Create a new dictionary for daily data
daily_t2m = Dict(
    "latitude" => t2m["latitude"],
    "longitude" => t2m["longitude"],
    "time" => daily_dates,
    "t2m" => daily_temperature
)
# Print the first few elements of the new daily data
daily_t2m
```

```{julia}
temp_lat = reverse(daily_t2m["latitude"])
temp_lon = daily_t2m["longitude"]
temp_time = daily_t2m["time"][732:16365]
temp = daily_t2m["t2m"][732:16365]
```
```{julia}
reshaped_t2m = permutedims(reshape(temp, length(temp_lat), length(temp_lon), :), (3, 1, 2))
```

```{julia}
@assert temp_time == precip_time
```
```{julia}
time = Date.(precip_time)
```

```julia
# Here I'm reshaping the t2m dictionary (from get_data.jl) into a matrix
# Extract t2m values
temp = t2m["t2m"]

# Assuming the other vectors are consistent in length
rows = length(daily_t2m["time"])
cols = length(daily_t2m["latitude"]) * length(daily_t2m["longitude"])

# Reshape t2m into a matrix
temp_matrix = reshape(t2m, rows, cols)
```

# 3. Splitting Data
```{julia}
#ADD IN NOTES HERE
test_start_date = Date(2010, 12, 18) #CHANGE THIS
test_start_index = searchsortedfirst(time, test_start_date)
```
```{julia}
# Here I'm splitting my data into training & testing sets

precip_train = precip[:, :, 1:test_start_index - 1]

precip_test = precip[:, :, test_start_index:end]
```
```{julia}
temp_train = temp[1:test_start_index - 1]

temp_test = temp[test_start_index:end]
```
```{julia}
time_train = time[1:test_start_index - 1]
time_test = time[test_start_index:end]
```

# 4. Preprocessing
```{julia}

# ADD IN EXPLANATION AS TO WHAT IM PREPROCESSING & WHY
