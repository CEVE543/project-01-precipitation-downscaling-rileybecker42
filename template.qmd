---
title: "Project 1"
subtitle: Precipitation Downscaling
jupyter: julia-1.9
date: 2023-11-13
author: Riley Becker (rb111)
---

# 1. Intro
```{julia}
import Pkg; Pkg.add("MultivariateStats")
import Pkg; Pkg.add("Plots")
import Pkg; Pkg.add("NCDatasets")
import Pkg; Pkg.add("StatsBase")
import Pkg; Pkg.add("Unitful")
```
```{julia}
import Pkg; Pkg.add("DataFrames")
```
```{julia}
using Dates
using MultivariateStats
using Plots
using NCDatasets
using StatsBase
using Unitful
using DataFrames
Plots.default(; margin=4Plots.mm, size=(700, 400), linewidth=2)
```

# 2. Data
## 2a. Precipitation Data
```{julia}
precip_ds = NCDataset("data/raw/precip_tx.nc") #loading in the precip_tx.nc dataset
```
```{julia}
# Here, I'm creating variables from the precip_tx.nc dataset.
precip_time = precip_ds["time"][732:end]
precip_time = Date.(precip_time)
precip_lon = precip_ds["lon"][:]
precip_lat = precip_ds["lat"][:]
precip_lat = reverse(precip_lat) #The latitude needs to be reversed.
precip = (precip_ds["precip"][:, :, 732:end])*.1u"mm" #this precipitation data is in millimeters, so I'm adding in units.
precip = reverse(precip, dims=2) #Because we reversed the latitude, we need to do the same in the second dimension of the precipitation data.
```
```{julia}
close(precip_ds) #closing the dataset
```

## 2b. Temperature Data
### Loading in Temperature Data
```{julia}
function open_mfdataset(files::Vector{String}, variable_name::AbstractString)
    # Lists to store variable data, time data, and other coordinate data
    var_data_list = []
    time_data_list = []
    coords_data_dict = Dict()

    # Open the first file to get the coordinate names (excluding time and the main variable)
    ds = Dataset(files[1])
    dimnames = keys(ds.dim)
    coord_names = setdiff(collect(dimnames), [variable_name, "time"])
    close(ds)

    # Initialize lists for each coordinate in coords_data_dict
    for coord in coord_names
        coords_data_dict[coord] = []
    end

    # Open each file, extract data, and store in lists
    for file in files
        ds = Dataset(file)

        # Store variable and time data
        push!(var_data_list, ds[variable_name][:])
        push!(time_data_list, ds["time"][:])

        # Store other coordinate data
        for coord in coord_names
            push!(coords_data_dict[coord], ds[coord][:])
        end

        close(ds)
    end

    # Pair variable data with time data and sort by time
    sorted_pairs = sort(collect(zip(time_data_list, var_data_list)); by=x -> x[1])
    sorted_time_data = [pair[1] for pair in sorted_pairs]
    sorted_var_data = [pair[2] for pair in sorted_pairs]

    # Concatenate sorted data
    concatenated_data_dict = Dict(
        variable_name => vcat(sorted_var_data...), "time" => vcat(sorted_time_data...)
    )

    # Concatenate coordinate data and add to the dictionary
    for coord in coord_names
        concatenated_data_dict[coord] = vcat(coords_data_dict[coord]...)
    end

    return concatenated_data_dict
end
```
```{julia}
using CDSAPI
base_path = "data/raw"
files = ["2m_temperature_1979.nc","2m_temperature_1980.nc","2m_temperature_1981.nc","2m_temperature_1982.nc","2m_temperature_1983.nc","2m_temperature_1984.nc", "2m_temperature_1985.nc","2m_temperature_1986.nc", "2m_temperature_1987.nc", "2m_temperature_1988.nc", "2m_temperature_1989.nc", "2m_temperature_1990.nc", "2m_temperature_1991.nc", "2m_temperature_1992.nc","2m_temperature_1993.nc","2m_temperature_1994.nc","2m_temperature_1995.nc","2m_temperature_1996.nc","2m_temperature_1997.nc","2m_temperature_1998.nc","2m_temperature_1999.nc","2m_temperature_2000.nc","2m_temperature_2001.nc","2m_temperature_2002.nc","2m_temperature_2003.nc","2m_temperature_2004.nc","2m_temperature_2005.nc","2m_temperature_2006.nc","2m_temperature_2007.nc","2m_temperature_2008.nc","2m_temperature_2009.nc","2m_temperature_2010.nc","2m_temperature_2011.nc","2m_temperature_2012.nc","2m_temperature_2013.nc","2m_temperature_2014.nc","2m_temperature_2015.nc","2m_temperature_2016.nc","2m_temperature_2017.nc","2m_temperature_2018.nc","2m_temperature_2019.nc","2m_temperature_2020.nc","2m_temperature_2021.nc","2m_temperature_2022.nc", "2m_temperature_2023.nc"]
```
```{julia}
file_paths = [joinpath(base_path, file) for file in files]
```
```{julia}
t2m = open_mfdataset(file_paths, "t2m")
```
### Temperature Variables
```{julia}
# ADD IN NOTES HERE
temp_time = t2m["time"]
temp_time = temp_time[732:end]
```
temp_time = hcat(temp_time)
```

```{julia}
temp_lon = t2m["longitude"]
temp_lon = hcat(temp_lon)
```

```{julia}
temp_lat = t2m["latitude"] #Just like precip_lat, temp_lat also needs to be reversed.
temp_lat = reverse(temp_lat)
```
temp_lat = hcat(temp_lat)
```

```{julia}
temp = t2m["t2m"]
```

```{julia}

start_date = Date(temp_time[1])
end_date = Date(temp_time[end])

n_days = (end_date) - (start_date)
```
lat_len = Int(length(temp_lat)/())
lon_len = Int(length(temp_lon)/())
time_len = length(temp_time)

temp = reshape(temp, lat_len, lon_len, time_len)
```


```{julia}
#INSERT FUNCTION THAT MAKES TEMP AND PRECIP TIME THE SAME
temp_date = Date.(temp_time)
temp_date = unique(temp_date)
```
```{julia}
@assert temp_date == precip_time
```
```{julia}
time = Date.(precip_time)
```
```julia
# Here I'm reshaping the t2m dictionary (from get_data.jl) into a matrix
# Extract t2m values
temp = t2m["t2m"]

# Assuming the other vectors are consistent in length
rows = length(t2m["time"])
cols = length(t2m["latitude"]) * length(t2m["longitude"])

# Reshape t2m into a matrix
temp_matrix = reshape(t2m, rows, cols)
```

# 3. Splitting Data
```{julia}
#ADD IN NOTES HERE
test_start_date = Date(2011, 1, 1) #CHANGE THIS
test_start_index = searchsortedfirst(time, test_start_date)
```
```{julia}
# Here I'm splitting my data into training & testing sets

precip_train = precip[:, :, 1:test_start_index - 1]

precip_test = precip[:, :, test_start_index:end]
```
```{julia}
temp_train = temp[:, :, 1:test_start_index - 1]

temp_test = temp[:, :, test_start_index:end]
```
```{julia}
time_train = time[1:test_start_index - 1]
time_test = time[test_start_index:end]
```

# 4. Preprocessing
```{julia}

# ADD IN EXPLANATION AS TO WHAT IM PREPROCESSING & WHY
